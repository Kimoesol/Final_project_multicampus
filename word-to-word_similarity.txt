<단어와 단어간의 유사도 분석>

* one-hot-encoding 방식 보다는 embedding 방식 활용 많이 하고 있다
* 단어 벡터 사전 (위키피디아 말뭉치, 페이스북의 자체 임베딩 기법[FastText])
* 자연어처리에 가장 많이 사용하는 gensim 라이브러리를 통해 단어 사전을 로드할 때, 각 언어에서 가장 많이 사용하는 단어 일부를 추출
-> 이렇게 로드한 gensim 모델을 다시 pkl로 저장해 개별 사전의 용량을 줄임 [영어의 경우, 6.2GB에서 600MB로 줄음]

* Word2Vec: 임베딩된 두 단어벡터의 내적이 코사인 유사도
